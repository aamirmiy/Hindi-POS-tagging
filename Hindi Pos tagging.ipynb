{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model Hindi POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting conllu\n",
      "  Downloading conllu-4.4-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: conllu\n",
      "Successfully installed conllu-4.4\n"
     ]
    }
   ],
   "source": [
    "!pip install conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse_incr\n",
    "from io import open\n",
    "file=open('hi_hdtb-ud-train.conllu','r',encoding='utf-8')\n",
    "ud_files=[]\n",
    "for tokenlist in parse_incr(file):\n",
    "    ud_files.append(tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(ud_files):\n",
    "    bank=[]\n",
    "    for sentence in ud_files:\n",
    "        tokens=[]\n",
    "        tags=[]\n",
    "\n",
    "        for token in sentence:\n",
    "            tokens.append(token['form'])\n",
    "            tags.append(token['upostag'])\n",
    "\n",
    "        bank.append((tokens,tags))\n",
    "    return bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=dataset(ud_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['इसे', 'नवाब', 'शाहजेहन', 'ने', 'बनवाया', 'था', '।']\n"
     ]
    }
   ],
   "source": [
    "print(train[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRON', 'NOUN', 'PROPN', 'ADP', 'VERB', 'AUX', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "print(bank[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['शरीफ',\n",
       " 'ने',\n",
       " 'पासपोर्ट',\n",
       " 'के',\n",
       " 'लिए',\n",
       " 'अपना',\n",
       " 'आवेदन',\n",
       " 'मुशर्रफ',\n",
       " 'की',\n",
       " 'पिछले',\n",
       " 'सप्ताह',\n",
       " 'सऊदी',\n",
       " 'अरब',\n",
       " 'की',\n",
       " 'यात्रा',\n",
       " 'के',\n",
       " 'समय',\n",
       " 'किया',\n",
       " 'था',\n",
       " '।']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank[13000][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(bank):\n",
    "    X,y=[],[]\n",
    "    for index in range(len(bank)):\n",
    "        X.append(bank[index][0])\n",
    "        y.append(bank[index][1])\n",
    "    return X,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=separate(bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13304"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13304"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['यह', 'एशिया', 'की', 'सबसे', 'बड़ी', 'मस्जिदों', 'में', 'से', 'एक', 'है', '।']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DET',\n",
       " 'PROPN',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'ADP',\n",
       " 'NUM',\n",
       " 'AUX',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "def flatten(list):\n",
    "  for i in list:\n",
    "    for j in i:\n",
    "      yield j\n",
    "L1=[[1,2,3],[4,5],[6,7,8,9]]\n",
    "flat=flatten(L1)\n",
    "print (list(flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('DET', 6081), ('PROPN', 34289), ('ADP', 59221), ('ADV', 2703), ('ADJ', 16459), ('NOUN', 62191), ('NUM', 5332), ('AUX', 20821), ('PUNCT', 18668), ('PRON', 11857), ('VERB', 27188), ('CCONJ', 5110), ('PART', 5610), ('SCONJ', 5389), ('X', 135), ('INTJ', 3)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "tag_set = flatten(y)\n",
    "count=Counter(tag_set)\n",
    "count.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('hi_hdtb-ud-test.conllu','r',encoding='utf-8')\n",
    "ud_files=[]\n",
    "for tokenlist in parse_incr(file):\n",
    "    ud_files.append(tokenlist)\n",
    "test_bank=[]\n",
    "for sentence in ud_files:\n",
    "    tokens=[]\n",
    "    tags=[]\n",
    "    \n",
    "    for token in sentence:\n",
    "        tokens.append(token['form'])\n",
    "        tags.append(token['upostag'])\n",
    "        \n",
    "    test_bank.append((tokens,tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('hi_hdtb-ud-dev.conllu','r',encoding='utf-8')\n",
    "ud_files=[]\n",
    "for tokenlist in parse_incr(file):\n",
    "    ud_files.append(tokenlist)\n",
    "dev_bank=[]\n",
    "for sentence in ud_files:\n",
    "    tokens=[]\n",
    "    tags=[]\n",
    "    \n",
    "    for token in sentence:\n",
    "        tokens.append(token['form'])\n",
    "        tags.append(token['upostag'])\n",
    "        \n",
    "    dev_bank.append((tokens,tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest,ytest=separate(test_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdev,ydev=separate(dev_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('PROPN', 4214), ('ADP', 7380), ('NOUN', 7928), ('PRON', 1473), ('ADJ', 2144), ('VERB', 3302), ('PUNCT', 2367), ('DET', 699), ('CCONJ', 682), ('PART', 722), ('AUX', 2613), ('ADV', 292), ('NUM', 715), ('SCONJ', 682), ('X', 4)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_set = flatten(ydev)\n",
    "count=Counter(tag_set)\n",
    "count.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('PRON', 1372), ('ADP', 7544), ('PROPN', 4438), ('PUNCT', 2420), ('CCONJ', 635), ('PART', 677), ('ADJ', 2043), ('NOUN', 8036), ('AUX', 2596), ('DET', 745), ('VERB', 3263), ('NUM', 693), ('ADV', 304), ('SCONJ', 655), ('X', 9)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_set = flatten(ytest)\n",
    "count=Counter(tag_set)\n",
    "count.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_list = set()\n",
    "tag_count = {}\n",
    "word_set = set()\n",
    "\n",
    "def transition_count(X,y):\n",
    "    global tag_list\n",
    "    global word_set\n",
    "    transition_dict = {}\n",
    "    global tag_count\n",
    "    for v in range(len(X)):\n",
    "        previous=\"start\"\n",
    "        for data in range(len(X[v])):\n",
    "            i=X[v][data]\n",
    "            word = i\n",
    "            word_set.add(word.lower())\n",
    "            tag = y[v][data]\n",
    "            tag_list.add(tag)\n",
    "\n",
    "            if tag in tag_count:\n",
    "                tag_count[tag]+=1\n",
    "            else:\n",
    "                tag_count[tag] = 1\n",
    "\n",
    "\n",
    "            if (previous + \"~tag~\" + tag) in transition_dict:\n",
    "                    transition_dict[previous + \"~tag~\" + tag] += 1\n",
    "                    previous = tag\n",
    "            else:\n",
    "                    transition_dict[previous + \"~tag~\" + tag] = 1\n",
    "                    previous = tag\n",
    "\n",
    "    return transition_dict,tag_count,tag_list,word_set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_m,tag_count,tag_list,word_set = transition_count(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_probability(X,y):\n",
    "    #count_dict = transition_count(X,y)\n",
    "    count_dict = transmission_m\n",
    "    prob_dict = {}\n",
    "    for key in count_dict:\n",
    "        den = 0\n",
    "        val = key.split(\"~tag~\")[0]\n",
    "        # Probabilty of a tagA to be followed by tagB out of all possible tags # \n",
    "        for key_2 in count_dict:\n",
    "            if key_2.split(\"~tag~\")[0] == val:\n",
    "                den += count_dict[key_2]\n",
    "        prob_dict[key] = Decimal(count_dict[key])/(den)\n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_smoothing(X,y):\n",
    "    transition_prob = transition_probability(X,y)\n",
    "    for tag in tag_list:\n",
    "    \t# if a tag does not occur as a start tag, then set its probability to be a start tag to minimum value #\n",
    "        if \"start\" + tag not in  transition_prob:\n",
    "            transition_prob[(\"start\" + \"~tag~\" + tag)] = Decimal(1) / Decimal(len(word_set) + tag_count[tag])\n",
    "    for tag1 in tag_list:\n",
    "        for tag2 in tag_list:\n",
    "        \t# if a particular tag combination does not exist in the dictionary, we set its probability to minimum#\n",
    "            if (tag1 +\"~tag~\" + tag2) not in transition_prob:\n",
    "                transition_prob[(tag1+\"~tag~\"+tag2)] = Decimal(1)/Decimal(len(word_set) + tag_count[tag1])\n",
    "    return transition_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_count(X,y):  \n",
    "    count_word = {}\n",
    "    for v in range(len(X)):\n",
    "        for data in range(len(X[v])):\n",
    "    #for value in train_data:\n",
    "        #for data in value:\n",
    "            i = X[v][data]\n",
    "            word = i\n",
    "            tag = y[v][data]\n",
    "            # map the words in the training set to their tagged POS #\n",
    "            if word.lower() + \"/\" + tag in count_word:\n",
    "                count_word[word.lower() + \"/\" + tag] +=1\n",
    "            else:\n",
    "                count_word[word.lower() + \"/\" + tag] = 1\n",
    "    return count_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_probability(X,y):\n",
    "    global tag_count\n",
    "    word_count = emission_count(X,y)\n",
    "    emission_prob_dict = {}\n",
    "    # calculate probability of a word to be a certain Tag out of all the possible tags that it can be #\n",
    "    for key in word_count:\n",
    "        emission_prob_dict[key] = Decimal(word_count[key])/tag_count[key.split(\"/\")[-1]]\n",
    "    return emission_prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_model = transition_smoothing(X,y)\n",
    "emission_model = emission_probability(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_algorithm(sentence, tag_list, transition_prob, emission_prob,tag_count, word_set):\n",
    "    global tag_set\n",
    "    # Get words from each sentence #\n",
    "    sentence = sentence.strip(\"\\n\")\n",
    "    word_list = sentence.split(\" \")\n",
    "    current_prob = {}\n",
    "    for tag in tag_list:\n",
    "        # transition probability #\n",
    "        tp = Decimal(0)\n",
    "        # Emission probability #\n",
    "        em = Decimal(0)\n",
    "        # Storing the probability of every tag to be starting tag #\n",
    "        if \"start~tag~\"+tag in transition_prob:\n",
    "            tp = Decimal(transition_prob[\"start~tag~\"+tag])\n",
    "        # Check for word in training data. If present, check the probability of the first word to be of given tag#\n",
    "        if word_list[0].lower() in word_set:\n",
    "            if (word_list[0].lower()+\"/\"+tag) in emission_prob:\n",
    "                em = Decimal(emission_prob[word_list[0].lower()+\"/\"+tag])\n",
    "                # Storing probability of current combination of tp and em #\n",
    "                current_prob[tag] = tp * em\n",
    "         # Check for word in training data. If absent then probability is just tp# \n",
    "        else:\n",
    "            em = Decimal(1) /(tag_count[tag] +len(word_set))\n",
    "            current_prob[tag] = tp\n",
    "\n",
    "    if len(word_list) == 1:\n",
    "        # Return max path if only one word in sentence #\n",
    "        max_path = max(current_prob, key=current_prob.get)\n",
    "        return max_path\n",
    "    else:\n",
    "        # Tracking from second word to last word #\n",
    "        for i in range(1, len(word_list)):\n",
    "            previous_prob = current_prob\n",
    "            current_prob = {}\n",
    "            locals()['dict{}'.format(i)] = {}\n",
    "            previous_tag = \"\"\n",
    "            for tag in tag_list:\n",
    "                if word_list[i].lower() in word_set:\n",
    "                    if word_list[i].lower()+\"/\"+tag in emission_prob:\n",
    "                        em = Decimal(emission_prob[word_list[i].lower()+\"/\"+tag])\n",
    "                        # Find the maximum probability using previous node's(tp*em)[i.e probability of reaching to the previous node] * tp * em (Bigram Model) #\n",
    "                        max_prob, previous_state = max((Decimal(previous_prob[previous_tag]) * Decimal(transition_prob[previous_tag + \"~tag~\" + tag]) * em, previous_tag) for previous_tag in previous_prob)\n",
    "                        current_prob[tag] = max_prob\n",
    "                        locals()['dict{}'.format(i)][previous_state + \"~\" + tag] = max_prob\n",
    "                        previous_tag = previous_state\n",
    "                else:\n",
    "                    em = Decimal(1) /(tag_count[tag] +len(word_set))\n",
    "                    max_prob, previous_state = max((Decimal(previous_prob[previous_tag]) * Decimal(transition_prob[previous_tag+\"~tag~\"+tag]) * em, previous_tag) for previous_tag in previous_prob)\n",
    "                    current_prob[tag] = max_prob\n",
    "                    locals()['dict{}'.format(i)][previous_state + \"~\" + tag] = max_prob\n",
    "                    previous_tag = previous_state\n",
    "\n",
    "            # if last word of sentence, then return path dicts of all words #\n",
    "            if i == len(word_list)-1:\n",
    "                max_path = \"\"\n",
    "                last_tag = max(current_prob, key=current_prob.get)\n",
    "                max_path = max_path + last_tag + \" \" + previous_tag\n",
    "                for j in range(len(word_list)-1,0,-1):\n",
    "                    for key in locals()['dict{}'.format(j)]:\n",
    "                        data = key.split(\"~\")\n",
    "                        if data[-1] == previous_tag:\n",
    "                            max_path = max_path + \" \" +data[0]\n",
    "                            previous_tag = data[0]\n",
    "                            break\n",
    "                result = max_path.split()\n",
    "                result.reverse()\n",
    "                return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'भारत एक देश है ।'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "भारत/PROPN \n",
      "एक/NUM \n",
      "देश/NOUN \n",
      "है/AUX \n",
      "।/PUNCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = viterbi_algorithm(sentence, tag_list, transition_model, emission_model,tag_count, word_set)\n",
    "word = sentence.split(\" \")\n",
    "tag = path.split(\" \")\n",
    "for j in range(0,len(word)):\n",
    "    if(j==len(word)-1):\n",
    "        print(word[j] + \"/\" + tag[j]+ u'\\n')\n",
    "    else:\n",
    "        print(word[j] + \"/\" + tag[j] + \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['इसके',\n",
       " 'अतिरिक्त',\n",
       " 'गुग्गुल',\n",
       " 'कुंड',\n",
       " ',',\n",
       " 'भीम',\n",
       " 'गुफा',\n",
       " 'तथा',\n",
       " 'भीमशिला',\n",
       " 'भी',\n",
       " 'दर्शनीय',\n",
       " 'स्थल',\n",
       " 'हैं',\n",
       " '।']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'CCONJ',\n",
       " 'PROPN',\n",
       " 'PART',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'AUX',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DET': 6081,\n",
       " 'PROPN': 34289,\n",
       " 'ADP': 59221,\n",
       " 'ADV': 2703,\n",
       " 'ADJ': 16459,\n",
       " 'NOUN': 62191,\n",
       " 'NUM': 5332,\n",
       " 'AUX': 20821,\n",
       " 'PUNCT': 18668,\n",
       " 'PRON': 11857,\n",
       " 'VERB': 27188,\n",
       " 'CCONJ': 5110,\n",
       " 'PART': 5610,\n",
       " 'SCONJ': 5389,\n",
       " 'X': 135,\n",
       " 'INTJ': 3}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'AUX',\n",
       " 'CCONJ',\n",
       " 'DET',\n",
       " 'INTJ',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PART',\n",
       " 'PRON',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'SCONJ',\n",
       " 'VERB',\n",
       " 'X'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(sentence, index):\n",
    "    return{\n",
    "      'word':sentence[index],\n",
    "      'is_first':index==0,\n",
    "      'is_last':index ==len(sentence)-1,\n",
    "      'prefix-1':sentence[index][0],\n",
    "      'prefix-2':sentence[index][:2],\n",
    "      'prefix-3':sentence[index][:3],\n",
    "      'prefix-3':sentence[index][:4],\n",
    "      'suffix-1':sentence[index][-1],\n",
    "      'suffix-2':sentence[index][-2:],\n",
    "      'suffix-3':sentence[index][-3:],\n",
    "      'suffix-3':sentence[index][-4:],\n",
    "      'next_word':sentence[index+1] if index<len(sentence)-1 else '',\n",
    "      'prev_word':'' if index == 0 else sentence[index-1],\n",
    "      'has_hyphen': '-' in sentence[index],\n",
    "      'is_numeric': sentence[index].isdigit()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=[]\n",
    "for index in range(len(X)):\n",
    "    arrange=[]\n",
    "    for i in range(len(X[index])):\n",
    "        arrange.append(extract_features(X[index],i))\n",
    "    xtrain.append(arrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'यह',\n",
       "  'is_first': True,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'य',\n",
       "  'prefix-2': 'यह',\n",
       "  'prefix-3': 'यह',\n",
       "  'suffix-1': 'ह',\n",
       "  'suffix-2': 'यह',\n",
       "  'suffix-3': 'यह',\n",
       "  'next_word': 'एशिया',\n",
       "  'prev_word': '',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False},\n",
       " {'word': 'एशिया',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ए',\n",
       "  'prefix-2': 'एश',\n",
       "  'prefix-3': 'एशिय',\n",
       "  'suffix-1': 'ा',\n",
       "  'suffix-2': 'या',\n",
       "  'suffix-3': 'शिया',\n",
       "  'next_word': 'की',\n",
       "  'prev_word': 'यह',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False},\n",
       " {'word': 'की',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'क',\n",
       "  'prefix-2': 'की',\n",
       "  'prefix-3': 'की',\n",
       "  'suffix-1': 'ी',\n",
       "  'suffix-2': 'की',\n",
       "  'suffix-3': 'की',\n",
       "  'next_word': 'सबसे',\n",
       "  'prev_word': 'एशिया',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False},\n",
       " {'word': 'सबसे',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'स',\n",
       "  'prefix-2': 'सब',\n",
       "  'prefix-3': 'सबसे',\n",
       "  'suffix-1': 'े',\n",
       "  'suffix-2': 'से',\n",
       "  'suffix-3': 'सबसे',\n",
       "  'next_word': 'बड़ी',\n",
       "  'prev_word': 'की',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False},\n",
       " {'word': 'बड़ी',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ब',\n",
       "  'prefix-2': 'बड',\n",
       "  'prefix-3': 'बड़ी',\n",
       "  'suffix-1': 'ी',\n",
       "  'suffix-2': '़ी',\n",
       "  'suffix-3': 'बड़ी',\n",
       "  'next_word': 'मस्जिदों',\n",
       "  'prev_word': 'सबसे',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False},\n",
       " {'word': 'मस्जिदों',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'म',\n",
       "  'prefix-2': 'मस',\n",
       "  'prefix-3': 'मस्ज',\n",
       "  'suffix-1': 'ं',\n",
       "  'suffix-2': 'ों',\n",
       "  'suffix-3': 'िदों',\n",
       "  'next_word': 'में',\n",
       "  'prev_word': 'बड़ी',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False},\n",
       " {'word': 'में',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'म',\n",
       "  'prefix-2': 'मे',\n",
       "  'prefix-3': 'में',\n",
       "  'suffix-1': 'ं',\n",
       "  'suffix-2': 'ें',\n",
       "  'suffix-3': 'में',\n",
       "  'next_word': 'से',\n",
       "  'prev_word': 'मस्जिदों',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False},\n",
       " {'word': 'से',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'स',\n",
       "  'prefix-2': 'से',\n",
       "  'prefix-3': 'से',\n",
       "  'suffix-1': 'े',\n",
       "  'suffix-2': 'से',\n",
       "  'suffix-3': 'से',\n",
       "  'next_word': 'एक',\n",
       "  'prev_word': 'में',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False},\n",
       " {'word': 'एक',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ए',\n",
       "  'prefix-2': 'एक',\n",
       "  'prefix-3': 'एक',\n",
       "  'suffix-1': 'क',\n",
       "  'suffix-2': 'एक',\n",
       "  'suffix-3': 'एक',\n",
       "  'next_word': 'है',\n",
       "  'prev_word': 'से',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False},\n",
       " {'word': 'है',\n",
       "  'is_first': False,\n",
       "  'is_last': False,\n",
       "  'prefix-1': 'ह',\n",
       "  'prefix-2': 'है',\n",
       "  'prefix-3': 'है',\n",
       "  'suffix-1': 'ै',\n",
       "  'suffix-2': 'है',\n",
       "  'suffix-3': 'है',\n",
       "  'next_word': '।',\n",
       "  'prev_word': 'एक',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False},\n",
       " {'word': '।',\n",
       "  'is_first': False,\n",
       "  'is_last': True,\n",
       "  'prefix-1': '।',\n",
       "  'prefix-2': '।',\n",
       "  'prefix-3': '।',\n",
       "  'suffix-1': '।',\n",
       "  'suffix-2': '।',\n",
       "  'suffix-3': '।',\n",
       "  'next_word': '',\n",
       "  'prev_word': 'है',\n",
       "  'has_hyphen': False,\n",
       "  'is_numeric': False}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DET',\n",
       " 'PROPN',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'ADP',\n",
       " 'NUM',\n",
       " 'AUX',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn_crfsuite in c:\\users\\aamir\\anaconda3\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: tabulate in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from sklearn_crfsuite) (0.8.9)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from sklearn_crfsuite) (0.9.7)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from sklearn_crfsuite) (4.46.0)\n",
      "Requirement already satisfied: six in c:\\users\\aamir\\anaconda3\\lib\\site-packages (from sklearn_crfsuite) (1.15.0)\n",
      "Started training \n",
      "Finished training \n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "!pip install sklearn_crfsuite\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "\n",
    "hindi_crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.20,\n",
    "    c2=0.3,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "print(\"Started training \")\n",
    "hindi_crf.fit(xtrain, y)\n",
    "print(\"Finished training \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=[]\n",
    "for index in range(len(Xtest)):\n",
    "    arrange=[]\n",
    "    for i in range(len(Xtest[index])):\n",
    "        arrange.append(extract_features(Xtest[index],i))\n",
    "    xtest.append(arrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##nltk##\n",
      "F1 score on Test Data\n",
      "0.9582940108541691\n",
      "Class wise score:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DET      0.967     0.969     0.968       745\n",
      "       PROPN      0.912     0.878     0.894      4438\n",
      "         ADP      0.989     0.993     0.991      7544\n",
      "         ADV      0.855     0.757     0.803       304\n",
      "         ADJ      0.911     0.926     0.919      2043\n",
      "        NOUN      0.931     0.946     0.939      8036\n",
      "         NUM      0.985     0.975     0.980       693\n",
      "         AUX      0.973     0.991     0.982      2596\n",
      "       PUNCT      1.000     1.000     1.000      2420\n",
      "        PRON      0.981     0.981     0.981      1372\n",
      "        VERB      0.982     0.971     0.976      3263\n",
      "       CCONJ      0.981     0.997     0.989       635\n",
      "        PART      0.989     0.969     0.979       677\n",
      "       SCONJ      0.988     0.989     0.989       655\n",
      "           X      0.250     0.333     0.286         9\n",
      "        INTJ      0.000     0.000     0.000         0\n",
      "\n",
      "   micro avg      0.958     0.958     0.958     35430\n",
      "   macro avg      0.856     0.855     0.855     35430\n",
      "weighted avg      0.958     0.958     0.958     35430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers\n",
    "print(\"##nltk##\")\n",
    "y_pred = hindi_crf.predict(xtest)\n",
    "print(\"F1 score on Test Data\")\n",
    "print(metrics.flat_f1_score(ytest, y_pred,average='weighted',labels=hindi_crf.classes_))\n",
    "#For the sake of clarification, we do the same for train data.\n",
    "y_pred_train=hindi_crf.predict(xtrain)\n",
    "print(\"F1 score on Training Data \")\n",
    "print(metrics.flat_f1_score(y, y_pred_train,average='weighted',labels=hindi_crf.classes_))\n",
    "\n",
    "# This presents class wise score. Helps see which classes (tags) are the ones with most problems.\n",
    "print(\"Class wise score:\")\n",
    "print(metrics.flat_classification_report(\n",
    "    ytest, y_pred, labels=hindi_crf.classes_, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958453288173864\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_accuracy_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958453288173864"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on Training Data \n",
      "0.9832879019997677\n"
     ]
    }
   ],
   "source": [
    "y_pred_train=hindi_crf.predict(xtrain)\n",
    "print(\"F1 score on Training Data \")\n",
    "print(metrics.flat_f1_score(y, y_pred_train,average='weighted',labels=hindi_crf.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class wise score:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DET      0.969     0.977     0.973      6081\n",
      "       PROPN      0.969     0.971     0.970     34289\n",
      "         ADP      0.994     0.996     0.995     59221\n",
      "         ADV      0.905     0.846     0.875      2703\n",
      "         ADJ      0.969     0.972     0.971     16459\n",
      "        NOUN      0.981     0.978     0.979     62191\n",
      "         NUM      0.983     0.992     0.988      5332\n",
      "         AUX      0.978     0.995     0.986     20821\n",
      "       PUNCT      1.000     1.000     1.000     18668\n",
      "        PRON      0.989     0.979     0.984     11857\n",
      "        VERB      0.992     0.980     0.986     27188\n",
      "       CCONJ      0.986     0.996     0.991      5110\n",
      "        PART      0.992     0.989     0.990      5610\n",
      "       SCONJ      0.986     0.997     0.991      5389\n",
      "           X      0.957     0.667     0.786       135\n",
      "        INTJ      1.000     0.667     0.800         3\n",
      "\n",
      "    accuracy                          0.983    281057\n",
      "   macro avg      0.978     0.938     0.954    281057\n",
      "weighted avg      0.983     0.983     0.983    281057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Class wise score:\")\n",
    "print(metrics.flat_classification_report(\n",
    "    y, y_pred_train, labels=hindi_crf.classes_, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9833378994296531\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_accuracy_score(y, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=hindi_crf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=list(flatten(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest=list(flatten(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='पत्तेदार सब्जियां आपके स्वास्थ्य के लिए अच्छी होती हैं ।'\n",
    "list1=[]\n",
    "list1.append(sentence.split())\n",
    "xtesting=[]\n",
    "for index in range(len(list1)):\n",
    "    arrange=[]\n",
    "    for i in range(len(list1[index])):\n",
    "        arrange.append(extract_features(list1[index],i))\n",
    "    xtesting.append(arrange)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'word': 'पत्तेदार',\n",
       "   'is_first': True,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'प',\n",
       "   'prefix-2': 'पत',\n",
       "   'prefix-3': 'पत्त',\n",
       "   'suffix-1': 'र',\n",
       "   'suffix-2': 'ार',\n",
       "   'suffix-3': 'ेदार',\n",
       "   'next_word': 'सब्जियां',\n",
       "   'prev_word': '',\n",
       "   'has_hyphen': False,\n",
       "   'is_numeric': False},\n",
       "  {'word': 'सब्जियां',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'स',\n",
       "   'prefix-2': 'सब',\n",
       "   'prefix-3': 'सब्ज',\n",
       "   'suffix-1': 'ं',\n",
       "   'suffix-2': 'ां',\n",
       "   'suffix-3': 'ियां',\n",
       "   'next_word': 'आपके',\n",
       "   'prev_word': 'पत्तेदार',\n",
       "   'has_hyphen': False,\n",
       "   'is_numeric': False},\n",
       "  {'word': 'आपके',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'आ',\n",
       "   'prefix-2': 'आप',\n",
       "   'prefix-3': 'आपके',\n",
       "   'suffix-1': 'े',\n",
       "   'suffix-2': 'के',\n",
       "   'suffix-3': 'आपके',\n",
       "   'next_word': 'स्वास्थ्य',\n",
       "   'prev_word': 'सब्जियां',\n",
       "   'has_hyphen': False,\n",
       "   'is_numeric': False},\n",
       "  {'word': 'स्वास्थ्य',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'स',\n",
       "   'prefix-2': 'स्',\n",
       "   'prefix-3': 'स्वा',\n",
       "   'suffix-1': 'य',\n",
       "   'suffix-2': '्य',\n",
       "   'suffix-3': '्थ्य',\n",
       "   'next_word': 'के',\n",
       "   'prev_word': 'आपके',\n",
       "   'has_hyphen': False,\n",
       "   'is_numeric': False},\n",
       "  {'word': 'के',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'क',\n",
       "   'prefix-2': 'के',\n",
       "   'prefix-3': 'के',\n",
       "   'suffix-1': 'े',\n",
       "   'suffix-2': 'के',\n",
       "   'suffix-3': 'के',\n",
       "   'next_word': 'लिए',\n",
       "   'prev_word': 'स्वास्थ्य',\n",
       "   'has_hyphen': False,\n",
       "   'is_numeric': False},\n",
       "  {'word': 'लिए',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ल',\n",
       "   'prefix-2': 'लि',\n",
       "   'prefix-3': 'लिए',\n",
       "   'suffix-1': 'ए',\n",
       "   'suffix-2': 'िए',\n",
       "   'suffix-3': 'लिए',\n",
       "   'next_word': 'अच्छी',\n",
       "   'prev_word': 'के',\n",
       "   'has_hyphen': False,\n",
       "   'is_numeric': False},\n",
       "  {'word': 'अच्छी',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'अ',\n",
       "   'prefix-2': 'अच',\n",
       "   'prefix-3': 'अच्छ',\n",
       "   'suffix-1': 'ी',\n",
       "   'suffix-2': 'छी',\n",
       "   'suffix-3': 'च्छी',\n",
       "   'next_word': 'होती',\n",
       "   'prev_word': 'लिए',\n",
       "   'has_hyphen': False,\n",
       "   'is_numeric': False},\n",
       "  {'word': 'होती',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ह',\n",
       "   'prefix-2': 'हो',\n",
       "   'prefix-3': 'होती',\n",
       "   'suffix-1': 'ी',\n",
       "   'suffix-2': 'ती',\n",
       "   'suffix-3': 'होती',\n",
       "   'next_word': 'हैं',\n",
       "   'prev_word': 'अच्छी',\n",
       "   'has_hyphen': False,\n",
       "   'is_numeric': False},\n",
       "  {'word': 'हैं',\n",
       "   'is_first': False,\n",
       "   'is_last': False,\n",
       "   'prefix-1': 'ह',\n",
       "   'prefix-2': 'है',\n",
       "   'prefix-3': 'हैं',\n",
       "   'suffix-1': 'ं',\n",
       "   'suffix-2': 'ैं',\n",
       "   'suffix-3': 'हैं',\n",
       "   'next_word': '।',\n",
       "   'prev_word': 'होती',\n",
       "   'has_hyphen': False,\n",
       "   'is_numeric': False},\n",
       "  {'word': '।',\n",
       "   'is_first': False,\n",
       "   'is_last': True,\n",
       "   'prefix-1': '।',\n",
       "   'prefix-2': '।',\n",
       "   'prefix-3': '।',\n",
       "   'suffix-1': '।',\n",
       "   'suffix-2': '।',\n",
       "   'suffix-3': '।',\n",
       "   'next_word': '',\n",
       "   'prev_word': 'हैं',\n",
       "   'has_hyphen': False,\n",
       "   'is_numeric': False}]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = hindi_crf.predict(xtesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'पत्तेदार सब्जियां आपके स्वास्थ्य के लिए अच्छी होती हैं ।'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NOUN', 'NOUN', 'PRON', 'NOUN', 'ADP', 'ADP', 'ADJ', 'VERB', 'AUX', 'PUNCT']]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "filename = 'crfhindi_1.sav'\n",
    "pickle.dump(hindi_crf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pprint,time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(list1, list2):\n",
    "      \n",
    "    merged_list = []\n",
    "    for i in range(max((len(list1), len(list2)))):\n",
    "  \n",
    "        while True:\n",
    "            try:\n",
    "                tup = (list1[i], list2[i])\n",
    "            except IndexError:\n",
    "                if len(list1) > len(list2):\n",
    "                    list2.append('')\n",
    "                    tup = (list1[i], list2[i])\n",
    "                elif len(list1) < len(list2):\n",
    "                    list1.append('')\n",
    "                    tup = (list1[i], list2[i])\n",
    "                continue\n",
    "  \n",
    "            merged_list.append(tup)\n",
    "            break\n",
    "    return merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xflat=list(flatten(X))\n",
    "yflat = list(flatten(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=merge(xflat,yflat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('यह', 'DET'),\n",
       " ('एशिया', 'PROPN'),\n",
       " ('की', 'ADP'),\n",
       " ('सबसे', 'ADV'),\n",
       " ('बड़ी', 'ADJ'),\n",
       " ('मस्जिदों', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('से', 'ADP'),\n",
       " ('एक', 'NUM'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('इसे', 'PRON'),\n",
       " ('नवाब', 'NOUN'),\n",
       " ('शाहजेहन', 'PROPN'),\n",
       " ('ने', 'ADP'),\n",
       " ('बनवाया', 'VERB'),\n",
       " ('था', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('इसका', 'PRON'),\n",
       " ('प्रवेश', 'NOUN'),\n",
       " ('द्वार', 'NOUN'),\n",
       " ('दो', 'NUM'),\n",
       " ('मंजिला', 'ADJ'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('जिसमें', 'PRON'),\n",
       " ('चार', 'NUM'),\n",
       " ('मेहराबें', 'NOUN'),\n",
       " ('हैं', 'AUX'),\n",
       " ('और', 'CCONJ'),\n",
       " ('मुख्य', 'ADJ'),\n",
       " ('प्रार्थना', 'NOUN'),\n",
       " ('हॉल', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('जाने', 'VERB'),\n",
       " ('के', 'ADP'),\n",
       " ('लिए', 'ADP'),\n",
       " ('9', 'NUM'),\n",
       " ('प्रवेश', 'NOUN'),\n",
       " ('द्वार', 'NOUN'),\n",
       " ('हैं', 'VERB'),\n",
       " ('।', 'PUNCT'),\n",
       " ('पूरी', 'ADJ'),\n",
       " ('इमारत', 'NOUN'),\n",
       " ('बेहद', 'ADV'),\n",
       " ('खूबसूरत', 'ADJ'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यहाँ', 'PRON'),\n",
       " ('लगने', 'VERB'),\n",
       " ('वाला', 'ADP'),\n",
       " ('तीन', 'NUM'),\n",
       " ('दिन', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('इज्तिमा', 'NOUN'),\n",
       " ('पूरे', 'ADJ'),\n",
       " ('देश', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('लोगों', 'NOUN'),\n",
       " ('को', 'ADP'),\n",
       " ('आमंत्रित', 'ADJ'),\n",
       " ('करता', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('शौकत', 'PROPN'),\n",
       " ('महल', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('सामने', 'ADP'),\n",
       " ('बड़ी', 'ADJ'),\n",
       " ('झील', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('किनारे', 'NOUN'),\n",
       " ('स्थित', 'ADJ'),\n",
       " ('वास्तुकला', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('यह', 'DET'),\n",
       " ('खूबसूरत', 'ADJ'),\n",
       " ('नमूना', 'NOUN'),\n",
       " ('कुदसिया', 'PROPN'),\n",
       " ('बेगम', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('काल', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('है', 'AUX'),\n",
       " ('जिन्हें', 'PRON'),\n",
       " ('गोहर', 'PROPN'),\n",
       " ('बेगम', 'PROPN'),\n",
       " ('भी', 'PART'),\n",
       " ('कहा', 'VERB'),\n",
       " ('जाता', 'AUX'),\n",
       " ('था', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('हिंदू', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('मुगल', 'NOUN'),\n",
       " ('कला', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('अद्भुत', 'ADJ'),\n",
       " ('संगम', 'NOUN'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('भारत', 'PROPN'),\n",
       " ('की', 'ADP'),\n",
       " ('अनूठी', 'ADJ'),\n",
       " ('राष्ट्रीय', 'ADJ'),\n",
       " ('संस्था', 'NOUN'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('मुख्य', 'ADJ'),\n",
       " ('रूप', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('यह', 'PRON'),\n",
       " ('प्रदर्शन', 'NOUN'),\n",
       " ('कला', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('दृश्य', 'NOUN'),\n",
       " ('कला', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('केंद्र', 'NOUN'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('इसे', 'PRON'),\n",
       " ('चार्ल्स', 'NOUN'),\n",
       " ('कोरिया', 'PROPN'),\n",
       " ('ने', 'ADP'),\n",
       " ('डिजाइन', 'NOUN'),\n",
       " ('किया', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('विशाल', 'ADJ'),\n",
       " ('क्षेत्र', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('फैले', 'VERB'),\n",
       " ('इस', 'DET'),\n",
       " ('भवन', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('आस', 'NOUN'),\n",
       " ('-', 'PUNCT'),\n",
       " ('पास', 'ADP'),\n",
       " ('का', 'ADP'),\n",
       " ('प्राकृतिक', 'ADJ'),\n",
       " ('सौंदर्य', 'NOUN'),\n",
       " ('इसे', 'PRON'),\n",
       " ('और', 'DET'),\n",
       " ('भी', 'PART'),\n",
       " ('भव्य', 'ADJ'),\n",
       " ('बनाता', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यहीं', 'PRON'),\n",
       " ('पर', 'ADP'),\n",
       " ('एक', 'NUM'),\n",
       " ('कला', 'NOUN'),\n",
       " ('संग्रहालय', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('कला', 'NOUN'),\n",
       " ('दीर्घा', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('फाइन', 'NOUN'),\n",
       " ('आर्ट', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('लिए', 'ADP'),\n",
       " ('कार्यशाला', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('एक', 'NUM'),\n",
       " ('थिएटर', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('अंतरंग', 'ADJ'),\n",
       " ('और', 'CCONJ'),\n",
       " ('बहिरंग', 'ADJ'),\n",
       " ('ऑडिटोरियम', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('रिहर्सल', 'NOUN'),\n",
       " ('कक्ष', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('भारतीय', 'ADJ'),\n",
       " ('कविताओं', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('पुस्तकालय', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('शास्त्रीय', 'ADJ'),\n",
       " ('और', 'CCONJ'),\n",
       " ('लोक', 'ADJ'),\n",
       " ('संगीत', 'NOUN'),\n",
       " ('संग्रहालय', 'NOUN'),\n",
       " ('भी', 'PART'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('सोमवार', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('अलावा', 'ADP'),\n",
       " ('पूरे', 'ADJ'),\n",
       " ('सप्ताह', 'NOUN'),\n",
       " ('दोपहर', 'NOUN'),\n",
       " ('2', 'NUM'),\n",
       " ('बजे', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('रात', 'NOUN'),\n",
       " ('8', 'NUM'),\n",
       " ('बजे', 'NOUN'),\n",
       " ('तक', 'ADP'),\n",
       " ('खुला', 'VERB'),\n",
       " ('रहता', 'AUX'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('एक', 'NUM'),\n",
       " ('अनूठा', 'ADJ'),\n",
       " ('संग्रहालय', 'NOUN'),\n",
       " ('है', 'AUX'),\n",
       " ('जो', 'PRON'),\n",
       " ('200', 'NUM'),\n",
       " ('एकड़', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('श्यामला', 'PROPN'),\n",
       " ('हिल्स', 'PROPN'),\n",
       " ('पर', 'ADP'),\n",
       " ('बड़ी', 'ADJ'),\n",
       " ('झील', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('सामने', 'ADP'),\n",
       " ('फैला', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('एक', 'NUM'),\n",
       " ('प्रागैतिहासिक', 'ADJ'),\n",
       " ('स्थल', 'NOUN'),\n",
       " ('पर', 'ADP'),\n",
       " ('है', 'AUX'),\n",
       " ('और', 'CCONJ'),\n",
       " ('विश्व', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('अपनी', 'PRON'),\n",
       " ('तरह', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('एक', 'NUM'),\n",
       " ('ही', 'PART'),\n",
       " ('संग्रहालय', 'NOUN'),\n",
       " ('है', 'AUX'),\n",
       " ('जो', 'PRON'),\n",
       " ('प्रागैतिहासिक', 'ADJ'),\n",
       " ('चित्रकला', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('सज्जित', 'ADJ'),\n",
       " ('गुफाओं', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('समीप', 'ADP'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('और', 'CCONJ'),\n",
       " ('इस', 'DET'),\n",
       " ('तरह', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('यह', 'PRON'),\n",
       " ('वस्तुओं', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('परंपराओं', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('जीवंत', 'ADJ'),\n",
       " ('रूप', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('जुड़ा', 'VERB'),\n",
       " ('हुआ', 'AUX'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यहाँ', 'PRON'),\n",
       " ('आदिवासी', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('समुद्र', 'NOUN'),\n",
       " ('किनारे', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('रेगिस्तान', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('हिमालय', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('आवासों', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('नमूने', 'NOUN'),\n",
       " ('भी', 'PART'),\n",
       " ('बनाए', 'VERB'),\n",
       " ('गए', 'AUX'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यहाँ', 'PRON'),\n",
       " ('संग्रहालय', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('पुस्तकालय', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('दृश्य', 'ADJ'),\n",
       " ('-', 'PUNCT'),\n",
       " ('श्रृव्य', 'ADJ'),\n",
       " ('आर्काइव', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('कंप्यूटरीकृत', 'ADJ'),\n",
       " ('कक्ष', 'NOUN'),\n",
       " ('व', 'CCONJ'),\n",
       " ('प्रजातीय', 'ADJ'),\n",
       " ('नमूनों', 'NOUN'),\n",
       " ('को', 'ADP'),\n",
       " ('देखा', 'VERB'),\n",
       " ('जाता', 'AUX'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यहाँ', 'PRON'),\n",
       " ('मध्य', 'PROPN'),\n",
       " ('प्रदेश', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('विभिन्न', 'ADJ'),\n",
       " ('हिस्सों', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('कला', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('खूबसूरत', 'ADJ'),\n",
       " ('नमूने', 'NOUN'),\n",
       " ('एकत्रित', 'ADJ'),\n",
       " ('करके', 'VERB'),\n",
       " ('रखे', 'VERB'),\n",
       " ('गए', 'AUX'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('संग्रहालय', 'NOUN'),\n",
       " ('सोमवार', 'PROPN'),\n",
       " ('को', 'ADP'),\n",
       " ('बंद', 'ADJ'),\n",
       " ('रहता', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('अरेरा', 'PROPN'),\n",
       " ('हिल्स', 'PROPN'),\n",
       " ('पर', 'ADP'),\n",
       " ('स्थित', 'ADJ'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('इससे', 'PRON'),\n",
       " ('लगा', 'VERB'),\n",
       " ('हुआ', 'AUX'),\n",
       " ('एक', 'NUM'),\n",
       " ('संग्रहालय', 'NOUN'),\n",
       " ('है', 'AUX'),\n",
       " ('जहाँ', 'PRON'),\n",
       " ('मध्यप्रदेश', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('रायसेन', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('सीहोर', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('मंदसौर', 'PROPN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('शहडोल', 'PROPN'),\n",
       " ('जिलों', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('एकत्रित', 'ADJ'),\n",
       " ('कला', 'NOUN'),\n",
       " ('नमूनों', 'NOUN'),\n",
       " ('को', 'ADP'),\n",
       " ('रखा', 'VERB'),\n",
       " ('गया', 'AUX'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'DET'),\n",
       " ('संग्रहालय', 'NOUN'),\n",
       " ('भी', 'PART'),\n",
       " ('सोमवार', 'PROPN'),\n",
       " ('को', 'ADP'),\n",
       " ('छोड़कर', 'VERB'),\n",
       " ('पूरे', 'ADJ'),\n",
       " ('सप्ताह', 'NOUN'),\n",
       " ('9', 'NUM'),\n",
       " ('बजे', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('5', 'NUM'),\n",
       " ('बजे', 'NOUN'),\n",
       " ('तक', 'ADP'),\n",
       " ('खुला', 'VERB'),\n",
       " ('रहता', 'AUX'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('बड़ी', 'ADJ'),\n",
       " ('झील', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('लगी', 'VERB'),\n",
       " ('पहाड़ी', 'NOUN'),\n",
       " ('पर', 'ADP'),\n",
       " ('यह', 'DET'),\n",
       " ('सफारी', 'NOUN'),\n",
       " ('उद्यान', 'NOUN'),\n",
       " ('स्थित', 'ADJ'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('445', 'NUM'),\n",
       " ('हैक्टेयर', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('फैला', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('प्राकृतिक', 'ADJ'),\n",
       " ('सुंदरता', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('बीच', 'ADP'),\n",
       " ('आप', 'PRON'),\n",
       " ('विभिन्न', 'ADJ'),\n",
       " ('प्रकार', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('शाकाहारी', 'ADJ'),\n",
       " ('और', 'CCONJ'),\n",
       " ('माँसाहारी', 'ADJ'),\n",
       " ('प्राणियों', 'NOUN'),\n",
       " ('को', 'ADP'),\n",
       " ('देखने', 'VERB'),\n",
       " ('का', 'ADP'),\n",
       " ('आनंद', 'NOUN'),\n",
       " ('उठा', 'VERB'),\n",
       " ('सकते', 'AUX'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('मंगलवार', 'PROPN'),\n",
       " ('को', 'ADP'),\n",
       " ('छोड़कर', 'VERB'),\n",
       " ('हर', 'DET'),\n",
       " ('दिन', 'NOUN'),\n",
       " ('सुबह', 'NOUN'),\n",
       " ('7', 'NUM'),\n",
       " ('से', 'ADP'),\n",
       " ('11', 'NUM'),\n",
       " ('और', 'CCONJ'),\n",
       " ('3', 'NUM'),\n",
       " ('से', 'ADP'),\n",
       " ('5', 'NUM'),\n",
       " ('बजे', 'NOUN'),\n",
       " ('शाम', 'NOUN'),\n",
       " ('तक', 'ADP'),\n",
       " ('खुला', 'VERB'),\n",
       " ('रहता', 'AUX'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('मूल', 'ADJ'),\n",
       " ('रूप', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('विज्ञान', 'NOUN'),\n",
       " ('संग्रहालय', 'NOUN'),\n",
       " ('है', 'AUX'),\n",
       " ('जो', 'PRON'),\n",
       " ('श्यामला', 'PROPN'),\n",
       " ('हिल्स', 'PROPN'),\n",
       " ('की', 'ADP'),\n",
       " ('खूबसूरती', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('बीच', 'ADP'),\n",
       " ('स्थित', 'ADJ'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यहाँ', 'PRON'),\n",
       " ('इन्वेंशन', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('फन', 'NOUN'),\n",
       " ('साइंस', 'NOUN'),\n",
       " ('गैलरी', 'NOUN'),\n",
       " ('हैं', 'AUX'),\n",
       " ('और', 'CCONJ'),\n",
       " ('एक', 'NUM'),\n",
       " ('तारामंडल', 'PROPN'),\n",
       " ('नाम', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('प्लेनेटेरियम', 'NOUN'),\n",
       " ('भी', 'PART'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('सोमवार', 'PROPN'),\n",
       " ('को', 'ADP'),\n",
       " ('छोड़कर', 'VERB'),\n",
       " ('हर', 'DET'),\n",
       " ('दिन', 'NOUN'),\n",
       " ('सुबह', 'NOUN'),\n",
       " ('10.30', 'NUM'),\n",
       " ('से', 'ADP'),\n",
       " ('6.30', 'NUM'),\n",
       " ('तक', 'ADP'),\n",
       " ('खुला', 'VERB'),\n",
       " ('रहता', 'AUX'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('शहर', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('बीच', 'ADP'),\n",
       " ('स्थित', 'ADJ'),\n",
       " ('चौक', 'PROPN'),\n",
       " ('में', 'ADP'),\n",
       " ('पुरानी', 'ADJ'),\n",
       " ('मस्जिद', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('हवेलियाँ', 'NOUN'),\n",
       " ('अतीत', 'NOUN'),\n",
       " ('की', 'ADP'),\n",
       " ('स्मृति', 'NOUN'),\n",
       " ('दिलाते', 'VERB'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('सँकरी', 'ADJ'),\n",
       " ('गलियों', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('स्थित', 'ADJ'),\n",
       " ('दुकानें', 'NOUN'),\n",
       " ('हैं', 'AUX'),\n",
       " ('जिनमें', 'PRON'),\n",
       " ('शिल्प', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('खजाने', 'NOUN'),\n",
       " ('खुले', 'VERB'),\n",
       " ('हुए', 'AUX'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यहाँ', 'PRON'),\n",
       " ('आप', 'PRON'),\n",
       " ('चाँदी', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('आभूषण', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('बीडवर्क', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('कढ़ाई', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('काम', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('सीक्वन', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('काम', 'NOUN'),\n",
       " ('खूबसूरत', 'ADJ'),\n",
       " ('अंदाज', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('देख', 'VERB'),\n",
       " ('और', 'CCONJ'),\n",
       " ('खरीद', 'VERB'),\n",
       " ('सकते', 'AUX'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('बड़ी', 'PROPN'),\n",
       " ('झील', 'PROPN'),\n",
       " ('छोटी', 'PROPN'),\n",
       " ('झील', 'PROPN'),\n",
       " ('से', 'ADP'),\n",
       " ('एक', 'NUM'),\n",
       " ('ओवरब्रिज', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('अलग', 'ADJ'),\n",
       " ('होती', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('म.प्र.', 'PROPN'),\n",
       " ('पर्यटन', 'PROPN'),\n",
       " ('बोट', 'PROPN'),\n",
       " ('क्लब', 'PROPN'),\n",
       " ('बड़ी', 'PROPN'),\n",
       " ('झील', 'PROPN'),\n",
       " ('में', 'ADP'),\n",
       " ('नौकायन', 'NOUN'),\n",
       " ('भी', 'PART'),\n",
       " ('करवाता', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('छोटी', 'PROPN'),\n",
       " ('झील', 'PROPN'),\n",
       " ('में', 'ADP'),\n",
       " ('एक', 'NUM'),\n",
       " ('मछली', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('आकार', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('एक्वेरियम', 'NOUN'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('कैसे', 'PRON'),\n",
       " ('पहुँचे', 'VERB'),\n",
       " ('?', 'PUNCT'),\n",
       " ('दिल्ली', 'PROPN'),\n",
       " ('ग्वालियर', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('इंदौर', 'PROPN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('मुंबई', 'PROPN'),\n",
       " ('से', 'ADP'),\n",
       " ('भोपाल', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('लिए', 'ADP'),\n",
       " ('नियमित', 'ADJ'),\n",
       " ('विमान', 'NOUN'),\n",
       " ('सेवा', 'NOUN'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('भोपाल', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('दिल्ली', 'PROPN'),\n",
       " ('-', 'PUNCT'),\n",
       " ('मद्रास', 'PROPN'),\n",
       " ('मेन', 'NOUN'),\n",
       " ('लाइन', 'NOUN'),\n",
       " ('पर', 'ADP'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('मुंबई', 'PROPN'),\n",
       " ('से', 'ADP'),\n",
       " ('इटारसी', 'PROPN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('झाँसी', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('रास्ते', 'NOUN'),\n",
       " ('दिल्ली', 'PROPN'),\n",
       " ('जाने', 'VERB'),\n",
       " ('वाली', 'ADP'),\n",
       " ('मुख्य', 'ADJ'),\n",
       " ('गाड़ियाँ', 'NOUN'),\n",
       " ('भोपाल', 'PROPN'),\n",
       " ('होकर', 'VERB'),\n",
       " ('जाती', 'VERB'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('भोपाल', 'PROPN'),\n",
       " ('तथा', 'CCONJ'),\n",
       " ('इंदौर', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('मांडू', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('उज्जैन', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('खजुराहो', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('पचमढ़ी', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('ग्वालियर', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('साँची', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('जबलपुर', 'PROPN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('शिवपुरी', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('बीच', 'ADP'),\n",
       " ('नियमित', 'ADJ'),\n",
       " ('बस', 'NOUN'),\n",
       " ('सेवाएँ', 'NOUN'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('ठहरने', 'VERB'),\n",
       " ('के', 'ADP'),\n",
       " ('लिए', 'ADP'),\n",
       " ('-', 'PUNCT'),\n",
       " ('मध्यप्रदेश', 'PROPN'),\n",
       " ('पर्यटन', 'PROPN'),\n",
       " ('विकास', 'PROPN'),\n",
       " ('निगम', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('होटल', 'NOUN'),\n",
       " ('तथा', 'CCONJ'),\n",
       " ('निजी', 'ADJ'),\n",
       " ('होटल', 'NOUN'),\n",
       " ('हैं', 'VERB'),\n",
       " ('।', 'PUNCT'),\n",
       " ('कब', 'PRON'),\n",
       " ('जाएँ', 'VERB'),\n",
       " ('?', 'PUNCT'),\n",
       " ('वर्ष', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('कभी', 'PRON'),\n",
       " ('भी', 'PART'),\n",
       " ('आप', 'PRON'),\n",
       " ('यहाँ', 'PRON'),\n",
       " ('जा', 'VERB'),\n",
       " ('सकते', 'AUX'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('ओरछा', 'PROPN'),\n",
       " ('का', 'ADP'),\n",
       " ('वैभव', 'NOUN'),\n",
       " ('पत्थरों', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('जैसे', 'PART'),\n",
       " ('कैद', 'NOUN'),\n",
       " ('हो', 'VERB'),\n",
       " ('गया', 'AUX'),\n",
       " ('है', 'AUX'),\n",
       " (',', 'PUNCT'),\n",
       " ('समय', 'NOUN'),\n",
       " ('यहाँ', 'PRON'),\n",
       " ('ठहरा', 'VERB'),\n",
       " ('हुआ', 'AUX'),\n",
       " ('लगता', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('और', 'CCONJ'),\n",
       " ('हम', 'PRON'),\n",
       " ('चले', 'VERB'),\n",
       " ('जाते', 'AUX'),\n",
       " ('हैं', 'AUX'),\n",
       " ('बरसों', 'NOUN'),\n",
       " ('बरस', 'NOUN'),\n",
       " ('पीछे', 'ADP'),\n",
       " (',', 'PUNCT'),\n",
       " ('मध्यकाल', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('एक', 'NUM'),\n",
       " ('शहर', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('.', 'PUNCT'),\n",
       " ('जहाँ', 'PRON'),\n",
       " ('के', 'ADP'),\n",
       " ('मंदिरों', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('महलों', 'NOUN'),\n",
       " ('की', 'ADP'),\n",
       " ('चमक', 'NOUN'),\n",
       " ('को', 'ADP'),\n",
       " ('समय', 'NOUN'),\n",
       " ('की', 'ADP'),\n",
       " ('धुंध', 'NOUN'),\n",
       " ('भी', 'PART'),\n",
       " ('धुँधला', 'VERB'),\n",
       " ('नहीं', 'PART'),\n",
       " ('सकी', 'AUX'),\n",
       " ('है', 'AUX'),\n",
       " ('.', 'PUNCT'),\n",
       " ('16', 'PROPN'),\n",
       " ('से', 'ADP'),\n",
       " ('17वीं', 'PROPN'),\n",
       " ('शताब्दी', 'PROPN'),\n",
       " ('में', 'ADP'),\n",
       " ('बुंदेला', 'PROPN'),\n",
       " ('शासकों', 'NOUN'),\n",
       " ('द्वारा', 'ADP'),\n",
       " ('बनवाई', 'VERB'),\n",
       " ('गई', 'AUX'),\n",
       " ('ये', 'DET'),\n",
       " ('इमारतें', 'NOUN'),\n",
       " ('प्राचीन', 'ADJ'),\n",
       " ('वैभव', 'NOUN'),\n",
       " ('को', 'ADP'),\n",
       " ('बयाँ', 'NOUN'),\n",
       " ('करती', 'VERB'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('ओरछा', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('16वीं', 'PROPN'),\n",
       " ('शताब्दी', 'PROPN'),\n",
       " ('में', 'ADP'),\n",
       " ('बुंदेला', 'PROPN'),\n",
       " ('राजपूत', 'NOUN'),\n",
       " ('रुद्र', 'PROPN'),\n",
       " ('प्रताप', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('द्वारा', 'ADP'),\n",
       " ('बसाया', 'VERB'),\n",
       " ('गया', 'AUX'),\n",
       " ('था', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('उनके', 'PRON'),\n",
       " ('आगे', 'ADP'),\n",
       " ('के', 'ADP'),\n",
       " ('राजाओं', 'NOUN'),\n",
       " ('ने', 'ADP'),\n",
       " ('शानदार', 'ADJ'),\n",
       " ('इमारतें', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('भवन', 'NOUN'),\n",
       " ('बनवाकर', 'VERB'),\n",
       " ('इसकी', 'PRON'),\n",
       " ('शान', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('चार', 'NUM'),\n",
       " ('चाँद', 'NOUN'),\n",
       " ('लगा', 'VERB'),\n",
       " ('दिए', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('जिनमें', 'PRON'),\n",
       " ('राजा', 'NOUN'),\n",
       " ('बीर', 'PROPN'),\n",
       " ('सिंह', 'PROPN'),\n",
       " ('जूदेव', 'PROPN'),\n",
       " ('का', 'ADP'),\n",
       " ('नाम', 'NOUN'),\n",
       " ('प्रमुख', 'ADJ'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('मंदिरों', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('महलों', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('बुंदेला', 'PROPN'),\n",
       " ('कला', 'NOUN'),\n",
       " ('की', 'ADP'),\n",
       " ('खूबसूरत', 'ADJ'),\n",
       " ('कलाकारी', 'NOUN'),\n",
       " ('देखते', 'VERB'),\n",
       " ('ही', 'PART'),\n",
       " ('बनती', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('लक्ष्मीनारायण', 'PROPN'),\n",
       " ('मंदिर', 'PROPN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('राजमहल', 'NOUN'),\n",
       " ('की', 'ADP'),\n",
       " ('दीवारें', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('छतों', 'NOUN'),\n",
       " ('की', 'ADP'),\n",
       " ('कलात्मकता', 'NOUN'),\n",
       " ('यहाँ', 'PRON'),\n",
       " ('की', 'ADP'),\n",
       " ('समृद्धि', 'NOUN'),\n",
       " ('की', 'ADP'),\n",
       " ('कहानी', 'NOUN'),\n",
       " ('कहतीं', 'VERB'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'DET'),\n",
       " ('महल', 'NOUN'),\n",
       " ('राजा', 'NOUN'),\n",
       " ('बीर', 'PROPN'),\n",
       " ('सिंह', 'PROPN'),\n",
       " ('जूदेव', 'PROPN'),\n",
       " ('ने', 'ADP'),\n",
       " ('17वीं', 'PROPN'),\n",
       " ('शताब्दी', 'PROPN'),\n",
       " ('में', 'ADP'),\n",
       " ('जहाँगीर', 'PROPN'),\n",
       " ('के', 'ADP'),\n",
       " ('ओरछा', 'PROPN'),\n",
       " ('आने', 'VERB'),\n",
       " ('के', 'ADP'),\n",
       " ('पहले', 'ADV'),\n",
       " ('बनवाया', 'VERB'),\n",
       " ('था', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('इसकी', 'PRON'),\n",
       " ('मजबूत', 'ADJ'),\n",
       " ('दीवारों', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('साथ', 'ADP'),\n",
       " ('नाजुकी', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('बनी', 'VERB'),\n",
       " ('हुई', 'AUX'),\n",
       " ('छतरियाँ', 'NOUN'),\n",
       " ('कमाल', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('संतुलन', 'NOUN'),\n",
       " ('बनाती', 'VERB'),\n",
       " ('हैं', 'AUX'),\n",
       " ('और', 'CCONJ'),\n",
       " ('इससे', 'PRON'),\n",
       " ('पूरी', 'ADJ'),\n",
       " ('इमारत', 'NOUN'),\n",
       " ('अत्यंत', 'ADV'),\n",
       " ('समृद्धिपूर्ण', 'ADJ'),\n",
       " ('प्रभाव', 'NOUN'),\n",
       " ('देती', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('चतुर्भुज', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('आकार', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('यह', 'DET'),\n",
       " ('महल', 'NOUN'),\n",
       " ('17वीं', 'PROPN'),\n",
       " ('शताब्दी', 'PROPN'),\n",
       " ('में', 'ADP'),\n",
       " ('मधुकर', 'PROPN'),\n",
       " ('शाह', 'PROPN'),\n",
       " ('ने', 'ADP'),\n",
       " ('बनवाया', 'VERB'),\n",
       " ('था', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('अंदर', 'ADV'),\n",
       " ('धार्मिकता', 'NOUN'),\n",
       " ('को', 'ADP'),\n",
       " ('लिए', 'VERB'),\n",
       " ('हुए', 'AUX'),\n",
       " ('शोख', 'ADJ'),\n",
       " ('रंगों', 'NOUN'),\n",
       " ('की', 'ADP'),\n",
       " ('अनोखी', 'ADJ'),\n",
       " ('शिल्प', 'NOUN'),\n",
       " ('कलाकृतियाँ', 'NOUN'),\n",
       " ('हैं', 'AUX'),\n",
       " ('।', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('दो', 'NUM'),\n",
       " ('कृत्रिम', 'ADJ'),\n",
       " ('तालाबों', 'NOUN'),\n",
       " ('मुंज', 'PROPN'),\n",
       " ('तालाब', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('कापुर', 'PROPN'),\n",
       " ('तालाब', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('बीच', 'ADP'),\n",
       " ('बना', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('.', 'PUNCT'),\n",
       " ('संभवतः', 'ADV'),\n",
       " ('यह', 'PRON'),\n",
       " ('सुल्तान', 'NOUN'),\n",
       " ('गयासुद्दीन', 'PROPN'),\n",
       " ('खिलजी', 'PROPN'),\n",
       " ('ने', 'ADP'),\n",
       " ('बड़े', 'ADJ'),\n",
       " ('हरम', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('रूप', 'ADP'),\n",
       " ('में', 'ADP'),\n",
       " ('बनवाया', 'VERB'),\n",
       " ('था', 'AUX'),\n",
       " ('.', 'PUNCT'),\n",
       " ('इसके', 'PRON'),\n",
       " ('खुले', 'ADJ'),\n",
       " ('गलियारे', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('बाहर', 'ADV'),\n",
       " ('निकली', 'VERB'),\n",
       " ('हुई', 'AUX'),\n",
       " ('बालकनी', 'NOUN'),\n",
       " ('और', 'CCONJ'),\n",
       " ('खूबसूरत', 'ADJ'),\n",
       " ('छत', 'NOUN'),\n",
       " ('शाही', 'ADJ'),\n",
       " ('शौक', 'NOUN'),\n",
       " ('को', 'ADP'),\n",
       " ('आसानी', 'NOUN'),\n",
       " ('से', 'ADP'),\n",
       " ('बयाँ', 'NOUN'),\n",
       " ('करते', 'VERB'),\n",
       " ('हैं', 'AUX'),\n",
       " ('.', 'PUNCT'),\n",
       " ('रात', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('समय', 'ADP'),\n",
       " ('इसे', 'PRON'),\n",
       " ('तवेली', 'PROPN'),\n",
       " ('महल', 'PROPN'),\n",
       " ('से', 'ADP'),\n",
       " ('निहारना', 'VERB'),\n",
       " ('बहुत', 'ADV'),\n",
       " ('सुखदायी', 'ADJ'),\n",
       " ('है', 'VERB'),\n",
       " ('.', 'PUNCT'),\n",
       " ('यह', 'PRON'),\n",
       " ('दर्शकों', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('लिए', 'ADP'),\n",
       " ('बैठक', 'NOUN'),\n",
       " ('व्यवस्था', 'NOUN'),\n",
       " ('के', 'ADP'),\n",
       " ('रूप', 'ADP'),\n",
       " ('में', 'ADP'),\n",
       " ('बनाया', 'VERB'),\n",
       " ('गया', 'AUX'),\n",
       " ('था', 'AUX'),\n",
       " ('.', 'PUNCT'),\n",
       " ('इसके', 'PRON'),\n",
       " ('आस', 'NOUN'),\n",
       " ('-', 'PUNCT'),\n",
       " ('पास', 'ADP'),\n",
       " ('की', 'ADP'),\n",
       " ('दीवारें', 'NOUN'),\n",
       " ('कुछ', 'DET'),\n",
       " ('झुकी', 'VERB'),\n",
       " ('हुई', 'AUX'),\n",
       " ('सी', 'PART'),\n",
       " ('हैं', 'AUX'),\n",
       " ('जिसके', 'PRON'),\n",
       " ('कारण', 'ADP'),\n",
       " ('इसे', 'PRON'),\n",
       " ('हिंडोला', 'PROPN'),\n",
       " ('महल', 'PROPN'),\n",
       " ('कहा', 'VERB'),\n",
       " ('जाता', 'AUX'),\n",
       " ('है', 'AUX'),\n",
       " ('.', 'PUNCT'),\n",
       " ('बलुआ', 'PROPN'),\n",
       " ('पत्थरों', 'NOUN'),\n",
       " ('में', 'ADP'),\n",
       " ('नक्काशी', 'NOUN'),\n",
       " ('का', 'ADP'),\n",
       " ('नायाब', 'ADJ'),\n",
       " ('नमूना', 'NOUN'),\n",
       " ('यहाँ', 'PRON'),\n",
       " ('देखने', 'VERB'),\n",
       " ('को', 'ADP'),\n",
       " ('मिलता', 'VERB'),\n",
       " ('है', 'AUX'),\n",
       " ('.', 'PUNCT'),\n",
       " ('यहाँ', 'PRON'),\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "{'PRON', 'INTJ', 'PART', 'NUM', 'CCONJ', 'PROPN', 'ADJ', 'X', 'PUNCT', 'ADV', 'NOUN', 'SCONJ', 'DET', 'AUX', 'ADP', 'VERB'}\n"
     ]
    }
   ],
   "source": [
    "tags = {tag for word,tag in merged}\n",
    "print(len(tags))\n",
    "print(tags)\n",
    " \n",
    "# check total words in vocabulary\n",
    "vocab = {word for word,tag in merged}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_given_tag(word, tag, train_bag = merged):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    " \n",
    "     \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2_given_t1(t2, t1, train_bag = merged):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.40010121e-02 0.00000000e+00 4.66391146e-02 2.39520967e-02\n",
      "  2.02412088e-03 8.08804929e-02 9.91819203e-02 8.43383663e-04\n",
      "  6.24103891e-03 1.57712735e-02 3.17112267e-01 4.21691831e-04\n",
      "  4.14101370e-02 6.57839235e-03 1.55266926e-01 1.19676143e-01]\n",
      " [6.66666687e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.33333343e-01]\n",
      " [5.63279875e-02 0.00000000e+00 1.53297679e-02 6.22103401e-02\n",
      "  5.34759369e-04 5.81105165e-02 9.42958966e-02 8.91265576e-04\n",
      "  5.34759369e-03 1.17647061e-02 1.97504461e-01 1.42602494e-03\n",
      "  4.22459878e-02 8.60962570e-02 2.29946524e-02 3.44919801e-01]\n",
      " [5.62640664e-04 0.00000000e+00 5.43885957e-03 1.00337587e-01\n",
      "  5.25131263e-03 9.56489146e-03 1.20030008e-01 0.00000000e+00\n",
      "  1.89422350e-02 1.12528133e-03 6.75731421e-01 0.00000000e+00\n",
      "  9.75243840e-03 4.87621920e-03 3.91972996e-02 9.18979757e-03]\n",
      " [1.48532286e-01 0.00000000e+00 8.02348368e-03 3.81604694e-02\n",
      "  0.00000000e+00 2.86105663e-01 1.35420740e-01 0.00000000e+00\n",
      "  1.09589044e-02 1.58512723e-02 3.06262225e-01 3.91389430e-03\n",
      "  3.77690792e-02 0.00000000e+00 0.00000000e+00 9.00195725e-03]\n",
      " [5.62862726e-03 0.00000000e+00 5.48280776e-03 2.07063486e-03\n",
      "  3.66881490e-02 3.69185448e-01 1.28029399e-02 1.74983230e-04\n",
      "  6.59686774e-02 1.89565169e-03 6.62311539e-02 3.79130332e-04\n",
      "  3.14969826e-03 1.13739097e-03 4.15089399e-01 1.41153140e-02]\n",
      " [2.55179545e-03 0.00000000e+00 2.33306997e-02 1.45816877e-02\n",
      "  1.20906495e-02 4.36235480e-02 3.91882844e-02 0.00000000e+00\n",
      "  1.28804911e-02 3.64542194e-03 5.50154924e-01 6.07570328e-05\n",
      "  6.62251655e-03 4.35627922e-02 6.07570328e-05 2.47645661e-01]\n",
      " [7.40740728e-03 0.00000000e+00 3.70370373e-02 0.00000000e+00\n",
      "  0.00000000e+00 7.40740728e-03 6.66666701e-02 7.40740728e-03\n",
      "  7.40740728e-03 7.40740728e-03 9.62962955e-02 0.00000000e+00\n",
      "  2.22222228e-02 3.70370373e-02 0.00000000e+00 7.03703701e-01]\n",
      " [1.85718879e-01 1.07135202e-04 2.83908285e-03 2.14270409e-02\n",
      "  4.06578109e-02 3.20387840e-01 6.88343719e-02 1.01778447e-03\n",
      "  6.58881525e-03 2.13199053e-02 2.09449321e-01 2.53910441e-02\n",
      "  6.43346906e-02 2.67838011e-04 2.37840153e-02 7.82086980e-03]\n",
      " [6.91823885e-02 0.00000000e+00 1.05808362e-01 2.03477610e-02\n",
      "  1.84979651e-03 1.13947466e-01 1.57232702e-01 3.69959307e-04\n",
      "  3.29263769e-02 1.07288202e-02 1.85719565e-01 7.39918614e-04\n",
      "  6.40029609e-02 5.54938940e-03 7.39918575e-02 1.57602668e-01]\n",
      " [1.25420075e-02 0.00000000e+00 3.05510443e-02 6.73730904e-03\n",
      "  2.29936801e-02 5.38984723e-02 3.89606208e-02 8.68292816e-04\n",
      "  1.83306262e-02 5.78861916e-03 1.17653683e-01 2.89430958e-04\n",
      "  7.84679409e-03 1.81859117e-02 4.89781469e-01 1.75572023e-01]\n",
      " [2.36221939e-01 0.00000000e+00 4.63907979e-03 1.96696967e-02\n",
      "  1.85563185e-04 2.79458165e-01 7.49675259e-02 0.00000000e+00\n",
      "  2.17108931e-02 1.41028017e-02 2.36964181e-01 2.05975138e-02\n",
      "  8.59157518e-02 0.00000000e+00 3.71126371e-04 5.19576902e-03]\n",
      " [1.18401581e-02 0.00000000e+00 1.85824707e-02 2.30225287e-02\n",
      "  3.28893278e-04 5.26229246e-03 9.42279249e-02 1.64446639e-04\n",
      "  2.13780627e-03 1.90758090e-02 7.85397112e-01 0.00000000e+00\n",
      "  1.10179251e-02 6.24897238e-03 3.28893284e-03 1.94047038e-02]\n",
      " [2.31977329e-02 0.00000000e+00 1.39282458e-03 3.21790506e-03\n",
      "  4.21689637e-02 1.50809279e-02 5.37918461e-03 4.80284325e-05\n",
      "  5.13520002e-01 1.00859709e-03 2.49267574e-02 8.12641084e-02\n",
      "  3.31396190e-03 2.57384360e-01 1.94515157e-02 8.64511821e-03]\n",
      " [4.92224060e-02 1.68859024e-05 2.86047179e-02 3.95974405e-02\n",
      "  4.72805259e-04 1.07107274e-01 1.14503302e-01 5.74120670e-04\n",
      "  3.71489837e-03 2.01617666e-02 3.62945586e-01 7.26093771e-04\n",
      "  3.87700312e-02 4.32279101e-03 1.18876748e-01 1.10383138e-01]\n",
      " [1.35353832e-02 0.00000000e+00 8.23892932e-03 4.63439757e-03\n",
      "  1.82065610e-02 1.01883188e-02 1.19905844e-02 1.10342800e-04\n",
      "  1.30130947e-01 1.58158015e-03 3.75533327e-02 1.10416360e-01\n",
      "  4.78152139e-03 4.65977639e-01 1.55840814e-01 2.68133003e-02]]\n"
     ]
    }
   ],
   "source": [
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1] \n",
    "print(tags_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRON</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>PART</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>X</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>ADV</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADP</th>\n",
       "      <th>VERB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.084001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046639</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.080880</td>\n",
       "      <td>0.099182</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.317112</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.041410</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.155267</td>\n",
       "      <td>0.119676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>0.056328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0.062210</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.058111</td>\n",
       "      <td>0.094296</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.197504</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.042246</td>\n",
       "      <td>0.086096</td>\n",
       "      <td>0.022995</td>\n",
       "      <td>0.344920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.100338</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.009565</td>\n",
       "      <td>0.120030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018942</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.675731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.039197</td>\n",
       "      <td>0.009190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>0.148532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008023</td>\n",
       "      <td>0.038160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286106</td>\n",
       "      <td>0.135421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>0.015851</td>\n",
       "      <td>0.306262</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.037769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>0.005629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.036688</td>\n",
       "      <td>0.369185</td>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.065969</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.066231</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.415089</td>\n",
       "      <td>0.014115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>0.014582</td>\n",
       "      <td>0.012091</td>\n",
       "      <td>0.043624</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012880</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.550155</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.043563</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.247646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.096296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>0.185719</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>0.040658</td>\n",
       "      <td>0.320388</td>\n",
       "      <td>0.068834</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.006589</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.209449</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.064335</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>0.007821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.069182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105808</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.113947</td>\n",
       "      <td>0.157233</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.032926</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.185720</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.073992</td>\n",
       "      <td>0.157603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.012542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>0.022994</td>\n",
       "      <td>0.053898</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>0.117654</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.007847</td>\n",
       "      <td>0.018186</td>\n",
       "      <td>0.489781</td>\n",
       "      <td>0.175572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>0.236222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.019670</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.279458</td>\n",
       "      <td>0.074968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021711</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>0.236964</td>\n",
       "      <td>0.020598</td>\n",
       "      <td>0.085916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.005196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.011840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018582</td>\n",
       "      <td>0.023023</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.094228</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.019076</td>\n",
       "      <td>0.785397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.019405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>0.023198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.042169</td>\n",
       "      <td>0.015081</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.513520</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.024927</td>\n",
       "      <td>0.081264</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.257384</td>\n",
       "      <td>0.019452</td>\n",
       "      <td>0.008645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.049222</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.028605</td>\n",
       "      <td>0.039597</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.107107</td>\n",
       "      <td>0.114503</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.020162</td>\n",
       "      <td>0.362946</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.038770</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.118877</td>\n",
       "      <td>0.110383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.018207</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.130131</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.037553</td>\n",
       "      <td>0.110416</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.465978</td>\n",
       "      <td>0.155841</td>\n",
       "      <td>0.026813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PRON      INTJ      PART       NUM     CCONJ     PROPN       ADJ  \\\n",
       "PRON   0.084001  0.000000  0.046639  0.023952  0.002024  0.080880  0.099182   \n",
       "INTJ   0.666667  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "PART   0.056328  0.000000  0.015330  0.062210  0.000535  0.058111  0.094296   \n",
       "NUM    0.000563  0.000000  0.005439  0.100338  0.005251  0.009565  0.120030   \n",
       "CCONJ  0.148532  0.000000  0.008023  0.038160  0.000000  0.286106  0.135421   \n",
       "PROPN  0.005629  0.000000  0.005483  0.002071  0.036688  0.369185  0.012803   \n",
       "ADJ    0.002552  0.000000  0.023331  0.014582  0.012091  0.043624  0.039188   \n",
       "X      0.007407  0.000000  0.037037  0.000000  0.000000  0.007407  0.066667   \n",
       "PUNCT  0.185719  0.000107  0.002839  0.021427  0.040658  0.320388  0.068834   \n",
       "ADV    0.069182  0.000000  0.105808  0.020348  0.001850  0.113947  0.157233   \n",
       "NOUN   0.012542  0.000000  0.030551  0.006737  0.022994  0.053898  0.038961   \n",
       "SCONJ  0.236222  0.000000  0.004639  0.019670  0.000186  0.279458  0.074968   \n",
       "DET    0.011840  0.000000  0.018582  0.023023  0.000329  0.005262  0.094228   \n",
       "AUX    0.023198  0.000000  0.001393  0.003218  0.042169  0.015081  0.005379   \n",
       "ADP    0.049222  0.000017  0.028605  0.039597  0.000473  0.107107  0.114503   \n",
       "VERB   0.013535  0.000000  0.008239  0.004634  0.018207  0.010188  0.011991   \n",
       "\n",
       "              X     PUNCT       ADV      NOUN     SCONJ       DET       AUX  \\\n",
       "PRON   0.000843  0.006241  0.015771  0.317112  0.000422  0.041410  0.006578   \n",
       "INTJ   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "PART   0.000891  0.005348  0.011765  0.197504  0.001426  0.042246  0.086096   \n",
       "NUM    0.000000  0.018942  0.001125  0.675731  0.000000  0.009752  0.004876   \n",
       "CCONJ  0.000000  0.010959  0.015851  0.306262  0.003914  0.037769  0.000000   \n",
       "PROPN  0.000175  0.065969  0.001896  0.066231  0.000379  0.003150  0.001137   \n",
       "ADJ    0.000000  0.012880  0.003645  0.550155  0.000061  0.006623  0.043563   \n",
       "X      0.007407  0.007407  0.007407  0.096296  0.000000  0.022222  0.037037   \n",
       "PUNCT  0.001018  0.006589  0.021320  0.209449  0.025391  0.064335  0.000268   \n",
       "ADV    0.000370  0.032926  0.010729  0.185720  0.000740  0.064003  0.005549   \n",
       "NOUN   0.000868  0.018331  0.005789  0.117654  0.000289  0.007847  0.018186   \n",
       "SCONJ  0.000000  0.021711  0.014103  0.236964  0.020598  0.085916  0.000000   \n",
       "DET    0.000164  0.002138  0.019076  0.785397  0.000000  0.011018  0.006249   \n",
       "AUX    0.000048  0.513520  0.001009  0.024927  0.081264  0.003314  0.257384   \n",
       "ADP    0.000574  0.003715  0.020162  0.362946  0.000726  0.038770  0.004323   \n",
       "VERB   0.000110  0.130131  0.001582  0.037553  0.110416  0.004782  0.465978   \n",
       "\n",
       "            ADP      VERB  \n",
       "PRON   0.155267  0.119676  \n",
       "INTJ   0.000000  0.333333  \n",
       "PART   0.022995  0.344920  \n",
       "NUM    0.039197  0.009190  \n",
       "CCONJ  0.000000  0.009002  \n",
       "PROPN  0.415089  0.014115  \n",
       "ADJ    0.000061  0.247646  \n",
       "X      0.000000  0.703704  \n",
       "PUNCT  0.023784  0.007821  \n",
       "ADV    0.073992  0.157603  \n",
       "NOUN   0.489781  0.175572  \n",
       "SCONJ  0.000371  0.005196  \n",
       "DET    0.003289  0.019405  \n",
       "AUX    0.019452  0.008645  \n",
       "ADP    0.118877  0.110383  \n",
       "VERB   0.155841  0.026813  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "#the table is same as the transition table shown in section 3 of article\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "display(tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(words, train_bag = merged):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "     \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['X', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                 \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "             \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRON     0.666667\n",
       "INTJ     0.000000\n",
       "PART     0.000000\n",
       "NUM      0.000000\n",
       "CCONJ    0.000000\n",
       "PROPN    0.000000\n",
       "ADJ      0.000000\n",
       "X        0.000000\n",
       "PUNCT    0.000000\n",
       "ADV      0.000000\n",
       "NOUN     0.000000\n",
       "SCONJ    0.000000\n",
       "DET      0.000000\n",
       "AUX      0.000000\n",
       "ADP      0.000000\n",
       "VERB     0.333333\n",
       "Name: INTJ, dtype: float32"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df.loc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = list(set([pair[1] for pair in merged]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=list(flatten(Xtest))\n",
    "Ytest=list(flatten(ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('इस', 'DET')\n",
      "('बूटा', 'PROPN')\n",
      "('आडवाणी', 'PROPN')\n",
      "('पार्वती', 'PROPN')\n",
      "('अमेरिकी', 'ADJ')\n",
      "('इस', 'DET')\n",
      "('गौरतलब', 'ADJ')\n",
      "('इस', 'DET')\n",
      "('उन्होंने', 'PRON')\n",
      "('उपमुख्यमंत्री', 'PROPN')\n"
     ]
    }
   ],
   "source": [
    "state=[]\n",
    "for key, word in enumerate(test_tagged_words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        print(word)\n",
    "        #for tag in T:\n",
    "            #if key!=0:\n",
    "               #transition_p = tags_df.loc[state[-1], tag] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRON</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>PART</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>X</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>ADV</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADP</th>\n",
       "      <th>VERB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.084001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046639</td>\n",
       "      <td>0.023952</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.080880</td>\n",
       "      <td>0.099182</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.317112</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.041410</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.155267</td>\n",
       "      <td>0.119676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>0.056328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0.062210</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.058111</td>\n",
       "      <td>0.094296</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.197504</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.042246</td>\n",
       "      <td>0.086096</td>\n",
       "      <td>0.022995</td>\n",
       "      <td>0.344920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.100338</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.009565</td>\n",
       "      <td>0.120030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018942</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.675731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.039197</td>\n",
       "      <td>0.009190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>0.148532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008023</td>\n",
       "      <td>0.038160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.286106</td>\n",
       "      <td>0.135421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>0.015851</td>\n",
       "      <td>0.306262</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.037769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>0.005629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.036688</td>\n",
       "      <td>0.369185</td>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.065969</td>\n",
       "      <td>0.001896</td>\n",
       "      <td>0.066231</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.415089</td>\n",
       "      <td>0.014115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023331</td>\n",
       "      <td>0.014582</td>\n",
       "      <td>0.012091</td>\n",
       "      <td>0.043624</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012880</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.550155</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.043563</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.247646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.096296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>0.185719</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>0.040658</td>\n",
       "      <td>0.320388</td>\n",
       "      <td>0.068834</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.006589</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.209449</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.064335</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>0.007821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.069182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105808</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.113947</td>\n",
       "      <td>0.157233</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.032926</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.185720</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.073992</td>\n",
       "      <td>0.157603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.012542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>0.022994</td>\n",
       "      <td>0.053898</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>0.117654</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.007847</td>\n",
       "      <td>0.018186</td>\n",
       "      <td>0.489781</td>\n",
       "      <td>0.175572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>0.236222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.019670</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.279458</td>\n",
       "      <td>0.074968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021711</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>0.236964</td>\n",
       "      <td>0.020598</td>\n",
       "      <td>0.085916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.005196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.011840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018582</td>\n",
       "      <td>0.023023</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.094228</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.019076</td>\n",
       "      <td>0.785397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.019405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>0.023198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.042169</td>\n",
       "      <td>0.015081</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.513520</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.024927</td>\n",
       "      <td>0.081264</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.257384</td>\n",
       "      <td>0.019452</td>\n",
       "      <td>0.008645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.049222</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.028605</td>\n",
       "      <td>0.039597</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.107107</td>\n",
       "      <td>0.114503</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.020162</td>\n",
       "      <td>0.362946</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.038770</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>0.118877</td>\n",
       "      <td>0.110383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.013535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.018207</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>0.011991</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.130131</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.037553</td>\n",
       "      <td>0.110416</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.465978</td>\n",
       "      <td>0.155841</td>\n",
       "      <td>0.026813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PRON      INTJ      PART       NUM     CCONJ     PROPN       ADJ  \\\n",
       "PRON   0.084001  0.000000  0.046639  0.023952  0.002024  0.080880  0.099182   \n",
       "INTJ   0.666667  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "PART   0.056328  0.000000  0.015330  0.062210  0.000535  0.058111  0.094296   \n",
       "NUM    0.000563  0.000000  0.005439  0.100338  0.005251  0.009565  0.120030   \n",
       "CCONJ  0.148532  0.000000  0.008023  0.038160  0.000000  0.286106  0.135421   \n",
       "PROPN  0.005629  0.000000  0.005483  0.002071  0.036688  0.369185  0.012803   \n",
       "ADJ    0.002552  0.000000  0.023331  0.014582  0.012091  0.043624  0.039188   \n",
       "X      0.007407  0.000000  0.037037  0.000000  0.000000  0.007407  0.066667   \n",
       "PUNCT  0.185719  0.000107  0.002839  0.021427  0.040658  0.320388  0.068834   \n",
       "ADV    0.069182  0.000000  0.105808  0.020348  0.001850  0.113947  0.157233   \n",
       "NOUN   0.012542  0.000000  0.030551  0.006737  0.022994  0.053898  0.038961   \n",
       "SCONJ  0.236222  0.000000  0.004639  0.019670  0.000186  0.279458  0.074968   \n",
       "DET    0.011840  0.000000  0.018582  0.023023  0.000329  0.005262  0.094228   \n",
       "AUX    0.023198  0.000000  0.001393  0.003218  0.042169  0.015081  0.005379   \n",
       "ADP    0.049222  0.000017  0.028605  0.039597  0.000473  0.107107  0.114503   \n",
       "VERB   0.013535  0.000000  0.008239  0.004634  0.018207  0.010188  0.011991   \n",
       "\n",
       "              X     PUNCT       ADV      NOUN     SCONJ       DET       AUX  \\\n",
       "PRON   0.000843  0.006241  0.015771  0.317112  0.000422  0.041410  0.006578   \n",
       "INTJ   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "PART   0.000891  0.005348  0.011765  0.197504  0.001426  0.042246  0.086096   \n",
       "NUM    0.000000  0.018942  0.001125  0.675731  0.000000  0.009752  0.004876   \n",
       "CCONJ  0.000000  0.010959  0.015851  0.306262  0.003914  0.037769  0.000000   \n",
       "PROPN  0.000175  0.065969  0.001896  0.066231  0.000379  0.003150  0.001137   \n",
       "ADJ    0.000000  0.012880  0.003645  0.550155  0.000061  0.006623  0.043563   \n",
       "X      0.007407  0.007407  0.007407  0.096296  0.000000  0.022222  0.037037   \n",
       "PUNCT  0.001018  0.006589  0.021320  0.209449  0.025391  0.064335  0.000268   \n",
       "ADV    0.000370  0.032926  0.010729  0.185720  0.000740  0.064003  0.005549   \n",
       "NOUN   0.000868  0.018331  0.005789  0.117654  0.000289  0.007847  0.018186   \n",
       "SCONJ  0.000000  0.021711  0.014103  0.236964  0.020598  0.085916  0.000000   \n",
       "DET    0.000164  0.002138  0.019076  0.785397  0.000000  0.011018  0.006249   \n",
       "AUX    0.000048  0.513520  0.001009  0.024927  0.081264  0.003314  0.257384   \n",
       "ADP    0.000574  0.003715  0.020162  0.362946  0.000726  0.038770  0.004323   \n",
       "VERB   0.000110  0.130131  0.001582  0.037553  0.110416  0.004782  0.465978   \n",
       "\n",
       "            ADP      VERB  \n",
       "PRON   0.155267  0.119676  \n",
       "INTJ   0.000000  0.333333  \n",
       "PART   0.022995  0.344920  \n",
       "NUM    0.039197  0.009190  \n",
       "CCONJ  0.000000  0.009002  \n",
       "PROPN  0.415089  0.014115  \n",
       "ADJ    0.000061  0.247646  \n",
       "X      0.000000  0.703704  \n",
       "PUNCT  0.023784  0.007821  \n",
       "ADV    0.073992  0.157603  \n",
       "NOUN   0.489781  0.175572  \n",
       "SCONJ  0.000371  0.005196  \n",
       "DET    0.003289  0.019405  \n",
       "AUX    0.019452  0.008645  \n",
       "ADP    0.118877  0.110383  \n",
       "VERB   0.155841  0.026813  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)      #define a random seed to get same sentences when run multiple times\n",
    " \n",
    "# choose random 10 numbers\n",
    "rndom = [random.randint(1,len(m)) for x in range(10)]\n",
    " \n",
    "# list of 10 sents on which we test the model\n",
    "test_run = [m[i] for i in rndom]\n",
    " \n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    " \n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=[]\n",
    "for i in range(len(Xtest)):\n",
    "    mer=[]\n",
    "    mer.append(merge(Xtest[i],ytest[i]))\n",
    "    m.append(mer)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  11.152700424194336\n",
      "Viterbi Algorithm Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start=time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end=time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \",difference)\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    " \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('इस', 'DET'),\n",
       " ('बूटा', 'PROPN'),\n",
       " ('आडवाणी', 'PROPN'),\n",
       " ('पार्वती', 'PROPN'),\n",
       " ('अमेरिकी', 'ADJ'),\n",
       " ('इस', 'DET'),\n",
       " ('गौरतलब', 'ADJ'),\n",
       " ('इस', 'DET'),\n",
       " ('उन्होंने', 'PRON'),\n",
       " ('उपमुख्यमंत्री', 'PROPN')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('इसके', 'PRON'), ('अतिरिक्त', 'ADJ'), ('गुग्गुल', 'PRON'), ('कुंड', 'NOUN'), (',', 'PUNCT'), ('भीम', 'PRON'), ('गुफा', 'NOUN'), ('तथा', 'CCONJ'), ('भीमशिला', 'PRON'), ('भी', 'PART'), ('दर्शनीय', 'ADJ'), ('स्थल', 'NOUN'), ('हैं', 'AUX'), ('।', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "test_sent=\"कार्पोरेट जगत घोटालों से भरा हुआ है ।\"\n",
    "\n",
    "pred_tags_withoutRules= Viterbi(Xtest[0])\n",
    "\n",
    "print(pred_tags_withoutRules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['इसके',\n",
       " 'अतिरिक्त',\n",
       " 'गुग्गुल',\n",
       " 'कुंड',\n",
       " ',',\n",
       " 'भीम',\n",
       " 'गुफा',\n",
       " 'तथा',\n",
       " 'भीमशिला',\n",
       " 'भी',\n",
       " 'दर्शनीय',\n",
       " 'स्थल',\n",
       " 'हैं',\n",
       " '।']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON',\n",
       " 'ADP',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'PUNCT',\n",
       " 'PROPN',\n",
       " 'PROPN',\n",
       " 'CCONJ',\n",
       " 'PROPN',\n",
       " 'PART',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'AUX',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
